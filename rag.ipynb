{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "import openai\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the document\n",
    "document_dir = \"./data/\"\n",
    "filename = \"general_cooking.pdf\"\n",
    "file_path = os.path.join(document_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 1237 0 (offset 0)\n",
      "Ignoring wrong pointing object 2199 0 (offset 0)\n",
      "Ignoring wrong pointing object 8529 0 (offset 0)\n",
      "Ignoring wrong pointing object 12853 0 (offset 0)\n",
      "Ignoring wrong pointing object 30002 0 (offset 0)\n",
      "Ignoring wrong pointing object 31357 0 (offset 0)\n",
      "Ignoring wrong pointing object 31927 0 (offset 0)\n",
      "Ignoring wrong pointing object 31928 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and split the document\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split pages into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_65513/252236577.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB created with document embeddings.\n",
      "ChromaDB created with document embeddings.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "db1 = Chroma.from_documents(\n",
    "    chunks[:500], \n",
    "    embeddings, \n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"ChromaDB created with document embeddings.\")\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "db2 = Chroma.from_documents(\n",
    "    chunks[500:], \n",
    "    embeddings, \n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"ChromaDB created with document embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"what do i need to know when making noodles?\" # User question\n",
    "retrieved_docs = db1.similarity_search(user_question, k=10) # k is the number of documents to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_document_prompt(docs):\n",
    "    prompt = \"\\n\"\n",
    "    for doc in docs:\n",
    "        prompt += \"\\nContent:\\n\"\n",
    "        prompt += doc.page_content + \"\\n\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context formatted for GPT model.\n"
     ]
    }
   ],
   "source": [
    "# Generate a formatted context from the retrieved documents\n",
    "formatted_context = _get_document_prompt(retrieved_docs)\n",
    "print(\"Context formatted for GPT model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt constructed.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "## SYSTEM ROLE\n",
    "You are a kitchen aid and give assistance in finding recipes and answering questions about cooking, food, drinks, and nutrition.\n",
    "Format lists properly with bullet points or numbering.\n",
    "\n",
    "\n",
    "## USER QUESTION\n",
    "The user has asked: \n",
    "\"{user_question}\"\n",
    "\n",
    "## CONTEXT\n",
    "Here is the relevant content from the technical documents:  \n",
    "'''\n",
    "{formatted_context}\n",
    "'''\n",
    "\n",
    "## GUIDELINES\n",
    "1. **Accuracy**:  \n",
    "   - Only use the content in the `CONTEXT` section to answer.  \n",
    "   - If the answer cannot be found, explicitly state: \"The provided context does not contain this information.\"\n",
    "\n",
    "3. **Clarity**:  \n",
    "   - Use simple, professional, and concise language.  \n",
    "   - Format your response in Markdown for readability.  \n",
    "\n",
    "## TASK\n",
    "1. Answer the user's question **directly** if possible.  \n",
    "2. Point the user to relevant parts of the documentation.  \n",
    "3. Provide the response in the following format:\n",
    "\n",
    "## RESPONSE FORMAT\n",
    "'''\n",
    "# [Brief Title of the Answer]\n",
    "[Answer in simple, clear text.]\n",
    "'''\n",
    "\"\"\"\n",
    "print(\"Prompt constructed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPT client and parameters\n",
    "client = openai.OpenAI()\n",
    "model_params = {\n",
    "    'model': 'gpt-4o',\n",
    "    'temperature': 0.7,  # Increase creativity\n",
    "    'max_tokens': 4000,  # Allow for longer responses\n",
    "    'top_p': 0.9,        # Use nucleus sampling\n",
    "    'frequency_penalty': 0.5,  # Reduce repetition\n",
    "    'presence_penalty': 0.6    # Encourage new topics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'user', 'content': prompt}]\n",
    "completion = client.chat.completions.create(messages=messages, **model_params, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''\n",
      "# Key Considerations for Making Noodles\n",
      "\n",
      "When making noodles, there are several important aspects to consider based on the provided context:\n",
      "\n",
      "1. **Types of Flour**:\n",
      "   - Use durum wheat flour for dried pasta due to its high gluten content which makes it easier to roll out.\n",
      "   - For fresh egg pasta, standard bread wheat and eggs are typically used.\n",
      "\n",
      "2. **Dough Preparation**:\n",
      "   - Mix ingredients into a stiff dough and knead until smooth.\n",
      "   - Allow the dough to rest so that the flour particles absorb water and the gluten network develops.\n",
      "   - Roll the dough gently and repeatedly to form thin sheets, which helps organize and compress the gluten network.\n",
      "\n",
      "3. **Eggs in Pasta**:\n",
      "   - Eggs enhance color and richness; yolks provide fat for tenderness while egg whites add protein for firmness.\n",
      "   - Fresh pasta made with eggs should be cooked immediately or refrigerated due to potential salmonella risk.\n",
      "\n",
      "4. **Cooking Techniques**:\n",
      "   - Cook pasta al dente by stopping when the center remains slightly underdone, offering some resistance to chewing.\n",
      "   - Use plenty of boiling water (10 times the weight of pasta) for cooking.\n",
      "   - Stir noodles initially during cooking to prevent sticking.\n",
      "\n",
      "5. **Water Quality**:\n",
      "   - Hard water can increase stickiness; adding acid like lemon juice can adjust pH levels.\n",
      "\n",
      "The provided context does not contain detailed information about other noodle-making techniques or specific recipes beyond these general guidelines.\n",
      "'''\n"
     ]
    }
   ],
   "source": [
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
